{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106e62c0",
   "metadata": {},
   "source": [
    "## Optimizing Training Pipeline for Plant Pathology in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157554f9",
   "metadata": {},
   "source": [
    "To improve training performance in any deep learning pipeline, pytorch suggests few extra additions of codes in exitin pipeline.\n",
    "These additions are explained and mentioned well here in [Performance Tuning Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html) . In this notebook you will encounter few of such features with hands-on dedicated for GPU Computing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b270eec",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158fa290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31892df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3093836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Mixed Precision with Apex and Monitoring with Wandb\n",
    "import wandb\n",
    "from apex import amp\n",
    "from apex.optimizers import FusedAdam\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ead863",
   "metadata": {},
   "source": [
    "### Login to [Wandb](https://wandb.ai/home) \n",
    "\n",
    "Save API Key once login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134dfa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbgiddwani\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "wandb.login()\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdfbdb",
   "metadata": {},
   "source": [
    "### Set GPU Device if multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7a17f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 24 12:50:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    41W / 300W |     23MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    40W / 300W |      5MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    39W / 300W |      5MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    40W / 300W |      5MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c511dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab602d",
   "metadata": {},
   "source": [
    "### Use device for `cuda` or `cpu` based on availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff7968",
   "metadata": {},
   "source": [
    "```python\n",
    "cuda = torch.device('cuda')     # Default CUDA device\n",
    "cuda0 = torch.device('cuda:0')  # GPU 0 \n",
    "cuda2 = torch.device('cuda:2')  # GPU 2 (these are 0-indexed)\n",
    "\n",
    "\n",
    "x = torch.tensor([1., 2.], device=cuda0)\n",
    "# x.device is device(type='cuda', index=0)\n",
    "y = torch.tensor([1., 2.]).cuda()\n",
    "# y.device is device(type='cuda', index=0)\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    # allocates a tensor on GPU 1\n",
    "    a = torch.tensor([1., 2.], device=cuda)\n",
    "\n",
    "    # transfers a tensor from CPU to GPU 1\n",
    "    b = torch.tensor([1., 2.]).cuda()\n",
    "    # a.device and b.device are device(type='cuda', index=1)\n",
    "\n",
    "    # You can also use ``Tensor.to`` to transfer a tensor:\n",
    "    b2 = torch.tensor([1., 2.]).to(device=cuda)\n",
    "    # b.device and b2.device are device(type='cuda', index=1)\n",
    "\n",
    "    c = a + b\n",
    "    # c.device is device(type='cuda', index=1)\n",
    "\n",
    "    z = x + y\n",
    "    # z.device is device(type='cuda', index=0)\n",
    "\n",
    "    # even within a context, you can specify the device\n",
    "    # (or give a GPU index to the .cuda call)\n",
    "    d = torch.randn(2, device=cuda2)\n",
    "    e = torch.randn(2).to(cuda2)\n",
    "    f = torch.randn(2).cuda(cuda2)\n",
    "    # d.device, e.device, and f.device are all device(type='cuda', index=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b58b850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################\n",
    "#GPU using CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698873a",
   "metadata": {},
   "source": [
    "Create a Model Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c538a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"./saved\")\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e89618",
   "metadata": {},
   "source": [
    "Neccesaary and Performance Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3182c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    #Neccessary\n",
    "    TRAIN_CSV = \"../data/train.csv\",\n",
    "    TEST_CSV = \"../data/test.csv\",\n",
    "    IMAGE_PATH= \"../data/images\",\n",
    "    VOCAB = \"labels.json\",\n",
    "    saved_path=\"./saved/resnet18.pt\",\n",
    "    lr=0.001, \n",
    "    EPOCHS = 10,\n",
    "    BATCH_SIZE = 32,\n",
    "    IMAGE_SIZE = 224,\n",
    "    TRAIN_VALID_SPLIT = 0.2,\n",
    "#################################################################### \n",
    "    #For Perforamce Tuning\n",
    "    device=device,\n",
    "    SEED = 42,\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    "    USE_AMP = True,\n",
    "    channels_last=True)\n",
    "\n",
    "#(B, C, H, W) -> (B, H, W, C)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89e07f",
   "metadata": {},
   "source": [
    "### Initiate a Wandb Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ddfa70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">super-bird-84</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/bgiddwani/pytorch-lab\" target=\"_blank\">https://wandb.ai/bgiddwani/pytorch-lab</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/bgiddwani/pytorch-lab/runs/8fbztlsj\" target=\"_blank\">https://wandb.ai/bgiddwani/pytorch-lab/runs/8fbztlsj</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/home/Pytorch_CV_lab/notebooks/wandb/run-20220124_125002-8fbztlsj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initiate the Project and Entity\n",
    "wandb.init(project=\"pytorch-lab\", config=config)\n",
    "# access all HPs through wandb.config, so logging matches execution!\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c82ae",
   "metadata": {},
   "source": [
    "### Reproducibility: Mandate for Constant Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad8329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom operators, you might need to set python seed\n",
    "random.seed(config.SEED)\n",
    "# If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG \n",
    "np.random.seed(config.SEED)\n",
    "# Prevent RNG for CPU and GPU using torch\n",
    "torch.manual_seed(config.SEED)\n",
    "torch.cuda.manual_seed(config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d9015",
   "metadata": {},
   "source": [
    "### Create tensors directly on the target device\n",
    "\n",
    "Instead of calling `torch.rand(size).cuda()` to generate a random tensor, produce the output directly on the target device: `torch.rand(size, device=torch.device('cuda'))`.\n",
    "\n",
    "This is applicable to all functions which create new tensors and accept device argument: `torch.rand(), torch.zeros(), torch.full()` and similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4bb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.5 ms ± 936 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.randn((64, 3, 128, 72)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ba0444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.7 µs ± 109 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.randn((64, 3, 128, 72), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc052ec1",
   "metadata": {},
   "source": [
    "CUDA Convolution Benchmarking: Best Convolution Algo but may loose reproducibility if True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43cf3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If researcher and wants to reproducuce: False\n",
    "# If developer wants performance: True\n",
    "torch.backends.cudnn.benchmarks = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6e17f9",
   "metadata": {},
   "source": [
    "For Reproducibility in choosing a determinstic alternative algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f65888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0d3e2",
   "metadata": {},
   "source": [
    "### Enabling TF32 on Ampere GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf13ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The flag below controls whether to allow TF32 on matmul. This flag defaults to True.\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88c593",
   "metadata": {},
   "source": [
    "### Data Manipulation (Can be written Separately too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c00363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(config.TRAIN_CSV)\n",
    "test_df = pd.read_csv(config.TEST_CSV)\n",
    "f = open(config.VOCAB)\n",
    "vocab = json.load(f)\n",
    "\n",
    "df_fnames = train_df[\"image_id\"].append(test_df[\"image_id\"],ignore_index=True).tolist()\n",
    "def create_fname(path,extension):\n",
    "    def add_extension(fname):\n",
    "        return os.path.join(path,fname)+extension\n",
    "    return add_extension\n",
    "\n",
    "jpeg_extension_creator = create_fname(config.IMAGE_PATH,\".jpg\")\n",
    "train_df[\"image_id\"] = train_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "test_df[\"image_id\"] = test_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "for label in vocab:\n",
    "    train_df.loc[train_df[label] == 1, \"label\" ] = vocab[label] \n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c2d85",
   "metadata": {},
   "source": [
    "Data Split: Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7a1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_X, valid_df_X, train_df_y, valid_df_y = train_test_split(train_df[\"image_id\"],\n",
    "                                                                  train_df[\"label\"], \n",
    "                                                                  test_size=config.TRAIN_VALID_SPLIT, \n",
    "                                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5631046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split = pd.DataFrame(data={\"image_id\": train_df_X, \"label\": train_df_y})\n",
    "train_df_split.to_csv(\"../data/train_split.csv\", sep=',',index=False)\n",
    "\n",
    "valid_df_split = pd.DataFrame(data={\"image_id\": valid_df_X, \"label\": valid_df_y})\n",
    "valid_df_split.to_csv(\"../data/val_split.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e85891d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train input samples is 1456\n",
      "Number of valid input samples is 365\n",
      "Number of train output samples is 1456\n",
      "Number of valid output samples is 365\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train input samples is {}\".format(len(train_df_X)))\n",
    "print(\"Number of valid input samples is {}\".format(len(valid_df_X)))\n",
    "print(\"Number of train output samples is {}\".format(len(train_df_y)))\n",
    "print(\"Number of valid output samples is {}\".format(len(valid_df_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb493e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Image.open(train_df_X[0])).dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afeffd",
   "metadata": {},
   "source": [
    "```\n",
    "--> Image_File_Path (String) \n",
    "--> Image.open(File_Path) \n",
    "--> np.array(Image.open(File_Path))\n",
    "--> Images [0-255] uint8 \n",
    "--> [0-1]; float32 \n",
    "--> x - Mean_training_dataset  / Std_training_dataset```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62986851",
   "metadata": {},
   "source": [
    "Apply Data Transforms (Aumentations + Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "792db6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config.IMAGE_SIZE,config.IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((config.IMAGE_SIZE,config.IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f235bf",
   "metadata": {},
   "source": [
    "Custom Dataset and Dataloader for Plant Pathology Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a574e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantPathologyDataset(Dataset):\n",
    "    def __init__(self,x,y,vocab,transforms):\n",
    "        self.x = x # File Path in CSV\n",
    "        self.y = y # Label in CSV\n",
    "        self.vocab = vocab # Dictionary\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,idx): #File Name --> Preprocessed 3-D Tensor\n",
    "        fname = self.x.iloc[idx]        \n",
    "        label = self.y.iloc[idx]\n",
    "        image = Image.open(fname)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label #[3,224,224], [0-3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0abbfef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlantPathologyDataset(train_df_X, \n",
    "                                 train_df_y, \n",
    "                                 vocab,\n",
    "                                 data_transforms[\"train\"])\n",
    "valid_ds = PlantPathologyDataset(valid_df_X, \n",
    "                                 valid_df_y,\n",
    "                                 vocab,\n",
    "                                 data_transforms[\"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764c840",
   "metadata": {},
   "source": [
    "Optimizers:\n",
    "Gradient Descent:-\n",
    "    a. Stoicastic Gradient Descent bs = 1; 'n' number of examples. 'n / 1' number of data loader/steps for 1 Epoch\n",
    "    b. Mini-Batch Gradient Descent bs = 32; 'n' number of examples. 'n / 32' number of dataloaders/step for 1 Epoch \n",
    "    c. Full Batch Gradient Descent bs = total_number_of_samples number of dataloader/steps = 1 for 1 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1a220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2412663c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape #3,224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3947172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17487<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc78063e5e541f6ac96ee57897495ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Number of Iterations\n",
    "1456 / 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad6c19",
   "metadata": {},
   "source": [
    "### GPU Optimizations in Dataloader \n",
    "\n",
    "`torch.utils.data.DataLoader` supports asynchronous data loading and data augmentation in separate worker subprocesses. The default setting for DataLoader is `num_workers=0`, which means that the data loading is synchronous and done in the main process. As a result the main training process has to wait for the data to be available to continue the execution.\n",
    "\n",
    "Setting `num_workers > 0` enables asynchronous data loading and overlap between the training and data loading. `num_workers` should be tuned depending on the workload, CPU, GPU, and location of training data.\n",
    "\n",
    "DataLoader accepts `pin_memory` argument, which defaults to `False`. When using a GPU it’s better to set `pin_memory=True`, this instructs DataLoader to use pinned memory and enables faster and asynchronous memory copy from the host (CPU) to the GPU.\n",
    "\n",
    "- Set `pin_memory=True` \n",
    "- Set `num_workers=8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f14441",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=config.BATCH_SIZE,\n",
    "                      shuffle=True,\n",
    "                      num_workers=config.num_workers,\n",
    "                      pin_memory=config.pin_memory)\n",
    "valid_dl = DataLoader(valid_ds,\n",
    "                      batch_size=config.BATCH_SIZE,\n",
    "                      shuffle=False,\n",
    "                      num_workers=config.num_workers,\n",
    "                      pin_memory=config.pin_memory)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31154f3f",
   "metadata": {},
   "source": [
    "Load Model : Pretrained from torchvision model zoo or Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57365492",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "#Modify the classifier for agriculture data\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.3),\n",
    "                        nn.Linear(512,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df716e",
   "metadata": {},
   "source": [
    "### Enable `channels_last` memory format for computer vision models\n",
    "\n",
    "PyTorch 1.5 introduced support for channels_last memory format for convolutional networks. This format is meant to be used in conjunction with Automatic Mixed Precision (AMP) to further accelerate convolutional neural networks with Tensor Cores.\n",
    "\n",
    "Support for channels_last is experimental, but it’s expected to work for standard computer vision models (e.g. ResNet-50, SSD). To convert models to channels_last format follow Channels Last Memory Format Tutorial. The tutorial includes a section on converting existing models.\n",
    "\n",
    "Use `memory_format=torch.channels_last` after model initialization and input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b790c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel Last Optimization in Model\n",
    "if config.channels_last:\n",
    "    model = model.to(config.device, memory_format=torch.channels_last) #CHW --> #HWC\n",
    "else:\n",
    "    model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecfb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BackPropagation & Optimization\n",
    "## W_new = W_old - LR * W_gradient ; Gradient Descent Optimization Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff207455",
   "metadata": {},
   "source": [
    "### Apex for Fused Optimizer and Automatic Mixed Precision(AMP)\n",
    "\n",
    "FusedAdam does following\n",
    "- Fusion of the Adam update’s elementwise operations\n",
    "\n",
    "- A multi-tensor apply launch that batches the elementwise updates applied to all the model’s parameters into one or a few kernel launches.\n",
    "\n",
    "and\n",
    "\n",
    "Mixed precision leverages Tensor Cores and offers up to 3x overall speedup on Volta and newer GPU architectures. To use Tensor Cores AMP should be enabled and matrix/tensor dimensions should satisfy requirements for calling kernels that use Tensor Cores.\n",
    "\n",
    "Visit for More info on [Mixed Precision Training](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html)\n",
    "\n",
    "\n",
    "`amp.initialize` wraps the model and optimizer for mixed precision training. Note that that the model must already be on the correct GPU before calling `amp.initialize`. The opt_level goes from `O0`, which uses all floats, through `O3`, which uses half-precision throughout. `O1` and `O2` are different degrees of mixed-precision, the details of which can be found in the Apex [documentation](https://nvidia.github.io/apex/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a44ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.USE_AMP:\n",
    "    optimizer = FusedAdam(model.parameters(), config.lr)\n",
    "    model,optimizer = amp.initialize(model, optimizer, opt_level=\"O2\") #O0/O1/O2/O3\n",
    "else:\n",
    "    optimizer = optim.Adam(model.parameters(),lr=config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b658744",
   "metadata": {},
   "source": [
    "CrossEntropyLoss = Softmax(Final Activation Function for Normalizing the output of the FC Layer) + Negative Log Likelihood (NLL) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29819ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b398520",
   "metadata": {},
   "source": [
    "### Training Pipeline Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea689a96",
   "metadata": {},
   "source": [
    "Host to GPU copies are much faster when they originate from pinned (page-locked) memory. CPU tensors and storages expose a `pin_memory()` method, that returns a copy of the object, with data put in a pinned region.`\n",
    "\n",
    "Also, once you pin a tensor or storage, you can use asynchronous GPU copies. Just pass an additional `non_blocking=True` argument to a `to()` or a `cuda()` call. This can be used to overlap data transfers with computation.\n",
    "\n",
    "You can make the DataLoader return batches placed in pinned memory by passing `pin_memory=True` to its constructor.\n",
    "\n",
    "---\n",
    "\n",
    "Also, Mixed-precision training requires that the loss is scaled in order to prevent the gradients from underflowing. Apex does this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81061272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion,optimizer,num_epochs=10):\n",
    "    ############################################################\n",
    "    # tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    ############################################################\n",
    "\n",
    "    since = time.time()                                            \n",
    "    batch_ct = 0\n",
    "    example_ct = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        #Training\n",
    "        model.train()\n",
    "        for x,y in train_dl: #BS=32 ([BS,3,224,224], [BS,4])            \n",
    "            if config.channels_last:\n",
    "                x = x.to(config.device, memory_format=torch.channels_last) #CHW --> #HWC\n",
    "            else:\n",
    "                x = x.to(config.device)\n",
    "            y = y.to(config.device) #CHW --> #HWC\n",
    "            \n",
    "            #######################################################################\n",
    "            # The second code snippet does not zero the memory of each individual parameter, \n",
    "            # also the subsequent backward pass uses assignment instead of addition to store gradients,\n",
    "            # this reduces the number of memory operations.\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #optimizer.zero_grad(set_to_none=True)\n",
    "            ######################################################################\n",
    "            \n",
    "            train_logits = model(x) #Input = [BS,3,224,224] (Image) -- Model --> [BS,4] (Output Scores)\n",
    "            _, train_preds = torch.max(train_logits, 1)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "            \n",
    "            ########################################################################\n",
    "            # Apply backward pass on scaled loss function \n",
    "            if config.USE_AMP:\n",
    "                with amp.scale_loss(train_loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                    loss=scaled_loss\n",
    "            ########################################################################\n",
    "            else:\n",
    "                train_loss.backward() # Backpropagation this is where your W_gradient\n",
    "                loss=train_loss\n",
    "\n",
    "            optimizer.step() # W_new = W_old - LR * W_gradient \n",
    "            example_ct += len(x) \n",
    "            batch_ct += 1\n",
    "            \n",
    "            ########################################################################\n",
    "            # Stores Wandb Logs here\n",
    "            # Report metrics every 25th batch\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "            ########################################################################\n",
    "        \n",
    "        #validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        # Disable gradient calculation for validation or inference using torch.no_rad()\n",
    "        with torch.no_grad():\n",
    "            for x,y in valid_dl:\n",
    "                if config.channels_last:\n",
    "                    x = x.to(config.device, memory_format=torch.channels_last) #CHW --> #HWC\n",
    "                else:\n",
    "                    x = x.to(config.device)\n",
    "                y = y.to(config.device) #CHW --> #HWC\n",
    "                valid_logits = model(x)\n",
    "                _, valid_preds = torch.max(valid_logits, 1)\n",
    "                valid_loss = criterion(valid_logits,y)\n",
    "                running_loss += valid_loss.item() * x.size(0)\n",
    "                running_corrects += torch.sum(valid_preds == y.data)\n",
    "                total += y.size(0)\n",
    "                ########################################################################\n",
    "                # Test Accuracy Logs\n",
    "                wandb.log({\"test_accuracy\": running_corrects / total})\n",
    "                ########################################################################\n",
    "            \n",
    "        epoch_loss = running_loss / len(valid_ds)\n",
    "        epoch_acc = running_corrects.double() / len(valid_ds)\n",
    "        print(\"Validation Loss is {}\".format(epoch_loss))\n",
    "        print(\"Validation Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    torch.save(model.state_dict(), config.saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "    # where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, criterion, optimizer, num_epochs=config.EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8bcc9",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
