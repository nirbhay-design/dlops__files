{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8257788e",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a97203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41b071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc3991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Mixed Precision with Apex and Monitoring with Wandb\n",
    "import wandb\n",
    "from apex import amp\n",
    "from apex.optimizers import FusedAdam\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b695973",
   "metadata": {},
   "source": [
    "### Login to [Wandb](https://wandb.ai/home) \n",
    "\n",
    "Save API Key once login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c6a103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbgiddwani\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "wandb.login()\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9247ce2",
   "metadata": {},
   "source": [
    "### Set GPU Device if multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ca1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 14 19:49:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    56W / 300W |  21335MiB / 32505MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    41W / 300W |      5MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    39W / 300W |      5MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    40W / 300W |      5MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570b25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b6dc6",
   "metadata": {},
   "source": [
    "### Use device for `cuda` or `cpu` based on availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12f132",
   "metadata": {},
   "source": [
    "```python\n",
    "cuda = torch.device('cuda')     # Default CUDA device\n",
    "cuda0 = torch.device('cuda:0')  # GPU 0 \n",
    "cuda2 = torch.device('cuda:2')  # GPU 2 (these are 0-indexed)\n",
    "\n",
    "\n",
    "x = torch.tensor([1., 2.], device=cuda0)\n",
    "# x.device is device(type='cuda', index=0)\n",
    "y = torch.tensor([1., 2.]).cuda()\n",
    "# y.device is device(type='cuda', index=0)\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    # allocates a tensor on GPU 1\n",
    "    a = torch.tensor([1., 2.], device=cuda)\n",
    "\n",
    "    # transfers a tensor from CPU to GPU 1\n",
    "    b = torch.tensor([1., 2.]).cuda()\n",
    "    # a.device and b.device are device(type='cuda', index=1)\n",
    "\n",
    "    # You can also use ``Tensor.to`` to transfer a tensor:\n",
    "    b2 = torch.tensor([1., 2.]).to(device=cuda)\n",
    "    # b.device and b2.device are device(type='cuda', index=1)\n",
    "\n",
    "    c = a + b\n",
    "    # c.device is device(type='cuda', index=1)\n",
    "\n",
    "    z = x + y\n",
    "    # z.device is device(type='cuda', index=0)\n",
    "\n",
    "    # even within a context, you can specify the device\n",
    "    # (or give a GPU index to the .cuda call)\n",
    "    d = torch.randn(2, device=cuda2)\n",
    "    e = torch.randn(2).to(cuda2)\n",
    "    f = torch.randn(2).cuda(cuda2)\n",
    "    # d.device, e.device, and f.device are all device(type='cuda', index=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743fd938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################\n",
    "#GPU using CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81b563",
   "metadata": {},
   "source": [
    "Create a Model Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9392217",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"./saved\")\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535054ed",
   "metadata": {},
   "source": [
    "Neccesaary and Performance Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb9629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    #Neccessary\n",
    "    TRAIN_CSV = \"../data/train.csv\",\n",
    "    TEST_CSV = \"../data/test.csv\",\n",
    "    IMAGE_PATH= \"../data/images\",\n",
    "    VOCAB = \"labels.json\",\n",
    "    saved_path=\"./saved/resnet18.pt\",\n",
    "    lr=0.001, \n",
    "    EPOCHS = 10,\n",
    "    BATCH_SIZE = 32,\n",
    "    IMAGE_SIZE = 224,\n",
    "    TRAIN_VALID_SPLIT = 0.2,\n",
    "    device=device,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb6152",
   "metadata": {},
   "source": [
    "### Initiate a Wandb Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d77da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">elated-bush-37</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/bgiddwani/pytorch-lab\" target=\"_blank\">https://wandb.ai/bgiddwani/pytorch-lab</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/bgiddwani/pytorch-lab/runs/23hl2dgv\" target=\"_blank\">https://wandb.ai/bgiddwani/pytorch-lab/runs/23hl2dgv</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/home/Pytorch_Lab/notebooks/wandb/run-20220114_194925-23hl2dgv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initiate the Project and Entity\n",
    "wandb.init(project=\"pytorch-lab\", config=config)\n",
    "# access all HPs through wandb.config, so logging matches execution!\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7791e41",
   "metadata": {},
   "source": [
    "### Data Manipulation (Can be written Separately too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c141eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(config.TRAIN_CSV)\n",
    "test_df = pd.read_csv(config.TEST_CSV)\n",
    "f = open(config.VOCAB)\n",
    "vocab = json.load(f)\n",
    "\n",
    "df_fnames = train_df[\"image_id\"].append(test_df[\"image_id\"],ignore_index=True).tolist()\n",
    "def create_fname(path,extension):\n",
    "    def add_extension(fname):\n",
    "        return os.path.join(path,fname)+extension\n",
    "    return add_extension\n",
    "\n",
    "jpeg_extension_creator = create_fname(config.IMAGE_PATH,\".jpg\")\n",
    "train_df[\"image_id\"] = train_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "test_df[\"image_id\"] = test_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "for label in vocab:\n",
    "    train_df.loc[train_df[label] == 1, \"label\" ] = vocab[label] \n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c661f8",
   "metadata": {},
   "source": [
    "Data Split: Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b115336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_X, valid_df_X, train_df_y, valid_df_y = train_test_split(train_df[\"image_id\"],\n",
    "                                                                  train_df[\"label\"], \n",
    "                                                                  test_size=config.TRAIN_VALID_SPLIT, \n",
    "                                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31570bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split = pd.DataFrame(data={\"image_id\": train_df_X, \"label\": train_df_y})\n",
    "train_df_split.to_csv(\"../data/train_split.csv\", sep=',',index=False)\n",
    "\n",
    "valid_df_split = pd.DataFrame(data={\"image_id\": valid_df_X, \"label\": valid_df_y})\n",
    "valid_df_split.to_csv(\"../data/val_split.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c06d1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train input samples is 1456\n",
      "Number of valid input samples is 365\n",
      "Number of train output samples is 1456\n",
      "Number of valid output samples is 365\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train input samples is {}\".format(len(train_df_X)))\n",
    "print(\"Number of valid input samples is {}\".format(len(valid_df_X)))\n",
    "print(\"Number of train output samples is {}\".format(len(train_df_y)))\n",
    "print(\"Number of valid output samples is {}\".format(len(valid_df_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd8bdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Image.open(train_df_X[0])).dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9cbc04",
   "metadata": {},
   "source": [
    "```\n",
    "--> Image_File_Path (String) \n",
    "--> Image.open(File_Path) \n",
    "--> np.array(Image.open(File_Path))\n",
    "--> Images [0-255] uint8 \n",
    "--> [0-1]; float32 \n",
    "--> x - Mean_training_dataset  / Std_training_dataset```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3097e0",
   "metadata": {},
   "source": [
    "Apply Data Transforms (Aumentations + Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e64ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config.IMAGE_SIZE,config.IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((config.IMAGE_SIZE,config.IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51963ea",
   "metadata": {},
   "source": [
    "Custom Dataset and Dataloader for Plant Pathology Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a5c8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantPathologyDataset(Dataset):\n",
    "    def __init__(self,x,y,vocab,transforms):\n",
    "        self.x = x # File Path in CSV\n",
    "        self.y = y # Label in CSV\n",
    "        self.vocab = vocab # Dictionary\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,idx): #File Name --> Preprocessed 3-D Tensor\n",
    "        fname = self.x.iloc[idx]        \n",
    "        label = self.y.iloc[idx]\n",
    "        image = Image.open(fname)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label #[3,224,224], [0-3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6130c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlantPathologyDataset(train_df_X, \n",
    "                                 train_df_y, \n",
    "                                 vocab,\n",
    "                                 data_transforms[\"train\"])\n",
    "valid_ds = PlantPathologyDataset(valid_df_X, \n",
    "                                 valid_df_y,\n",
    "                                 vocab,\n",
    "                                 data_transforms[\"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d078c",
   "metadata": {},
   "source": [
    "Optimizers:\n",
    "Gradient Descent:-\n",
    "    a. Stoicastic Gradient Descent bs = 1; 'n' number of examples. 'n / 1' number of data loader/steps for 1 Epoch\n",
    "    b. Mini-Batch Gradient Descent bs = 32; 'n' number of examples. 'n / 32' number of dataloaders/step for 1 Epoch \n",
    "    c. Full Batch Gradient Descent bs = total_number_of_samples number of dataloader/steps = 1 for 1 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a449bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19728433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape #3,224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c762e747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Iterations\n",
    "1456 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50fa0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=config.BATCH_SIZE,\n",
    "                      shuffle=True,)\n",
    "valid_dl = DataLoader(valid_ds,\n",
    "                      batch_size=config.BATCH_SIZE,\n",
    "                      shuffle=False,)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe9cb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37493b79",
   "metadata": {},
   "source": [
    "Load Model : Pretrained from torchvision model zoo or Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a03fddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "#Modify the classifier for agriculture data\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.3),\n",
    "                        nn.Linear(512,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e6d64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e16ade23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BackPropagation & Optimization\n",
    "## W_new = W_old - LR * W_gradient ; Gradient Descent Optimization Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1fb4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b65f38",
   "metadata": {},
   "source": [
    "CrossEntropyLoss = Softmax(Final Activation Function for Normalizing the output of the FC Layer) + Negative Log Likelihood (NLL) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47dc91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da269b3",
   "metadata": {},
   "source": [
    "### Training Pipeline Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bd35c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion,optimizer,num_epochs=10):\n",
    "    ############################################################\n",
    "    # tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    ############################################################\n",
    "\n",
    "    since = time.time()                                            \n",
    "    batch_ct = 0\n",
    "    example_ct = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        #Training\n",
    "        model.train()\n",
    "        for x,y in train_dl: #BS=32 ([BS,3,224,224], [BS,4])            \n",
    "            x = x.to(config.device)\n",
    "            y = y.to(config.device) #CHW --> #HWC\n",
    "            \n",
    "            #######################################################################\n",
    "            # The second code snippet does not zero the memory of each individual parameter, \n",
    "            # also the subsequent backward pass uses assignment instead of addition to store gradients,\n",
    "            # this reduces the number of memory operations.\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ######################################################################\n",
    "            \n",
    "            train_logits = model(x) #Input = [BS,3,224,224] (Image) -- Model --> [BS,4] (Output Scores)\n",
    "            _, train_preds = torch.max(train_logits, 1)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "            \n",
    "\n",
    "            train_loss.backward() # Backpropagation this is where your W_gradient\n",
    "            loss=train_loss\n",
    "\n",
    "            optimizer.step() # W_new = W_old - LR * W_gradient \n",
    "            example_ct += len(x) \n",
    "            batch_ct += 1\n",
    "            \n",
    "            ########################################################################\n",
    "            # Stores Wandb Logs here\n",
    "            # Report metrics every 25th batch\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "            ########################################################################\n",
    "        \n",
    "        #validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        # Disable gradient calculation for validation or inference using torch.no_rad()\n",
    "        with torch.no_grad():\n",
    "            for x,y in valid_dl:\n",
    "                x = x.to(config.device)\n",
    "                y = y.to(config.device) #CHW --> #HWC\n",
    "                valid_logits = model(x)\n",
    "                _, valid_preds = torch.max(valid_logits, 1)\n",
    "                valid_loss = criterion(valid_logits,y)\n",
    "                running_loss += valid_loss.item() * x.size(0)\n",
    "                running_corrects += torch.sum(valid_preds == y.data)\n",
    "                total += y.size(0)\n",
    "                ########################################################################\n",
    "                # Test Accuracy Logs\n",
    "                wandb.log({\"test_accuracy\": running_corrects / total})\n",
    "                ########################################################################\n",
    "            \n",
    "        epoch_loss = running_loss / len(valid_ds)\n",
    "        epoch_acc = running_corrects.double() / len(valid_ds)\n",
    "        print(\"Validation Loss is {}\".format(epoch_loss))\n",
    "        print(\"Validation Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    torch.save(model.state_dict(), config.saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d7608a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "    # where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d67fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Loss after 00768 examples: 0.804\n",
      "Validation Loss is 1.3900960204535968\n",
      "Validation Accuracy is 0.715068493150685\n",
      "Epoch 1/9\n",
      "----------\n",
      "Loss after 01552 examples: 0.472\n",
      "Loss after 02352 examples: 0.615\n",
      "Validation Loss is 0.9468017408292587\n",
      "Validation Accuracy is 0.7205479452054795\n",
      "Epoch 2/9\n",
      "----------\n",
      "Loss after 03136 examples: 0.341\n",
      "Loss after 03936 examples: 0.596\n",
      "Validation Loss is 0.7305804726195662\n",
      "Validation Accuracy is 0.7972602739726028\n",
      "Epoch 3/9\n",
      "----------\n",
      "Loss after 04720 examples: 0.447\n",
      "Loss after 05520 examples: 0.388\n",
      "Validation Loss is 0.35017603968512523\n",
      "Validation Accuracy is 0.9095890410958904\n",
      "Epoch 4/9\n",
      "----------\n",
      "Loss after 06304 examples: 0.386\n",
      "Loss after 07104 examples: 0.588\n",
      "Validation Loss is 0.4408817216958085\n",
      "Validation Accuracy is 0.8904109589041096\n",
      "Epoch 5/9\n",
      "----------\n",
      "Loss after 07888 examples: 0.452\n",
      "Loss after 08688 examples: 0.575\n",
      "Validation Loss is 0.43791362414621327\n",
      "Validation Accuracy is 0.8876712328767123\n",
      "Epoch 6/9\n",
      "----------\n",
      "Loss after 09472 examples: 0.531\n",
      "Validation Loss is 0.28506757535346566\n",
      "Validation Accuracy is 0.9232876712328767\n",
      "Epoch 7/9\n",
      "----------\n",
      "Loss after 10256 examples: 0.499\n",
      "Loss after 11056 examples: 0.480\n",
      "Validation Loss is 0.38243405827104227\n",
      "Validation Accuracy is 0.8767123287671232\n",
      "Epoch 8/9\n",
      "----------\n",
      "Loss after 11840 examples: 0.319\n",
      "Loss after 12640 examples: 0.272\n",
      "Validation Loss is 0.4106718133573663\n",
      "Validation Accuracy is 0.8849315068493151\n",
      "Epoch 9/9\n",
      "----------\n",
      "Loss after 13424 examples: 0.163\n",
      "Loss after 14224 examples: 0.158\n",
      "Validation Loss is 0.3973487960965666\n",
      "Validation Accuracy is 0.873972602739726\n",
      "Training complete in 7m 48s\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, num_epochs=config.EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030857bc",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
