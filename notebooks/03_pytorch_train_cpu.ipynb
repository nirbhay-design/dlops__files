{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500791bf",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3747bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887f8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "400f073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Monitoring with Wandb\n",
    "import wandb\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789396d",
   "metadata": {},
   "source": [
    "### Login to [Wandb](https://wandb.ai/home) \n",
    "\n",
    "Save API Key once login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147dcf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "wandb.login()\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd92ca7",
   "metadata": {},
   "source": [
    "Create a Model Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb2035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"./saved\")\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234f673",
   "metadata": {},
   "source": [
    "Neccesaary and Performance Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b003e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    #Neccessary\n",
    "    TRAIN_CSV = \"../data/train.csv\",\n",
    "    TEST_CSV = \"../data/test.csv\",\n",
    "    IMAGE_PATH= \"../data/images\",\n",
    "    VOCAB = \"labels.json\",\n",
    "    saved_path=\"./saved/resnet18.pt\",\n",
    "    lr=0.001, \n",
    "    EPOCHS = 2,\n",
    "    BATCH_SIZE = 2,\n",
    "    IMAGE_SIZE = 224,\n",
    "    TRAIN_VALID_SPLIT = 0.2,\n",
    "    SEED = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8ed38",
   "metadata": {},
   "source": [
    "### Initiate a Wandb Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fa7491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">kind-snowflake-48</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/bgiddwani/pytorch-lab\" target=\"_blank\">https://wandb.ai/bgiddwani/pytorch-lab</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/bgiddwani/pytorch-lab/runs/g9rttllq\" target=\"_blank\">https://wandb.ai/bgiddwani/pytorch-lab/runs/g9rttllq</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/home/Pytorch_CV_lab/notebooks/wandb/run-20220118_131030-g9rttllq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initiate the Project and Entity\n",
    "wandb.init(project=\"pytorch-lab\", config=config)\n",
    "# access all HPs through wandb.config, so logging matches execution!\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a5aac",
   "metadata": {},
   "source": [
    "### Data Manipulation (Can be written Separately too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fe65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(config.TRAIN_CSV)\n",
    "test_df = pd.read_csv(config.TEST_CSV)\n",
    "f = open(config.VOCAB)\n",
    "vocab = json.load(f)\n",
    "\n",
    "df_fnames = train_df[\"image_id\"].append(test_df[\"image_id\"],ignore_index=True).tolist()\n",
    "def create_fname(path,extension):\n",
    "    def add_extension(fname):\n",
    "        return os.path.join(path,fname)+extension\n",
    "    return add_extension\n",
    "\n",
    "jpeg_extension_creator = create_fname(config.IMAGE_PATH,\".jpg\")\n",
    "train_df[\"image_id\"] = train_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "test_df[\"image_id\"] = test_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "for label in vocab:\n",
    "    train_df.loc[train_df[label] == 1, \"label\" ] = vocab[label] \n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052719ef",
   "metadata": {},
   "source": [
    "Data Split: Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "732cc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_X, valid_df_X, train_df_y, valid_df_y = train_test_split(train_df[\"image_id\"],\n",
    "                                                                  train_df[\"label\"], \n",
    "                                                                  test_size=config.TRAIN_VALID_SPLIT, \n",
    "                                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e1da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split = pd.DataFrame(data={\"image_id\": train_df_X, \"label\": train_df_y})\n",
    "train_df_split.to_csv(\"../data/train_split.csv\", sep=',',index=False)\n",
    "\n",
    "valid_df_split = pd.DataFrame(data={\"image_id\": valid_df_X, \"label\": valid_df_y})\n",
    "valid_df_split.to_csv(\"../data/val_split.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a89c1f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train input samples is 1456\n",
      "Number of valid input samples is 365\n",
      "Number of train output samples is 1456\n",
      "Number of valid output samples is 365\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train input samples is {}\".format(len(train_df_X)))\n",
    "print(\"Number of valid input samples is {}\".format(len(valid_df_X)))\n",
    "print(\"Number of train output samples is {}\".format(len(train_df_y)))\n",
    "print(\"Number of valid output samples is {}\".format(len(valid_df_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "901e56bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Image.open(train_df_X[0])).dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c79066",
   "metadata": {},
   "source": [
    "```\n",
    "--> Image_File_Path (String) \n",
    "--> Image.open(File_Path) \n",
    "--> np.array(Image.open(File_Path))\n",
    "--> Images [0-255] uint8 \n",
    "--> [0-1]; float32 \n",
    "--> x - Mean_training_dataset  / Std_training_dataset```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88e023",
   "metadata": {},
   "source": [
    "Apply Data Transforms (Aumentations + Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84dca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config.IMAGE_SIZE,config.IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((config.IMAGE_SIZE,config.IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad93be3",
   "metadata": {},
   "source": [
    "Custom Dataset and Dataloader for Plant Pathology Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b945c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantPathologyDataset(Dataset):\n",
    "    def __init__(self,x,y,vocab,transforms):\n",
    "        self.x = x # File Path in CSV\n",
    "        self.y = y # Label in CSV\n",
    "        self.vocab = vocab # Dictionary\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,idx): #File Name --> Preprocessed 3-D Tensor\n",
    "        fname = self.x.iloc[idx]        \n",
    "        label = self.y.iloc[idx]\n",
    "        image = Image.open(fname)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label #[3,224,224], [0-3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a65ea1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlantPathologyDataset(train_df_X, \n",
    "                                 train_df_y, \n",
    "                                 vocab,\n",
    "                                 data_transforms[\"train\"])\n",
    "valid_ds = PlantPathologyDataset(valid_df_X, \n",
    "                                 valid_df_y,\n",
    "                                 vocab,\n",
    "                                 data_transforms[\"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc39ad9",
   "metadata": {},
   "source": [
    "Optimizers:\n",
    "Gradient Descent:-\n",
    "    a. Stoicastic Gradient Descent bs = 1; 'n' number of examples. 'n / 1' number of data loader/steps for 1 Epoch\n",
    "    b. Mini-Batch Gradient Descent bs = 32; 'n' number of examples. 'n / 32' number of dataloaders/step for 1 Epoch \n",
    "    c. Full Batch Gradient Descent bs = total_number_of_samples number of dataloader/steps = 1 for 1 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caaa2c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2922bb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape #3,224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8b101ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Iterations\n",
    "1456 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590cf8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=config.BATCH_SIZE,\n",
    "                      shuffle=True,)\n",
    "valid_dl = DataLoader(valid_ds,\n",
    "                      batch_size=config.BATCH_SIZE,\n",
    "                      shuffle=False,)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99093ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcc183",
   "metadata": {},
   "source": [
    "Load Model : Pretrained from torchvision model zoo or Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8238da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "#Modify the classifier for agriculture data\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.3),\n",
    "                        nn.Linear(512,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9f6fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BackPropagation & Optimization\n",
    "## W_new = W_old - LR * W_gradient ; Gradient Descent Optimization Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "853f40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3c6f0",
   "metadata": {},
   "source": [
    "CrossEntropyLoss = Softmax(Final Activation Function for Normalizing the output of the FC Layer) + Negative Log Likelihood (NLL) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21c5b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b084f",
   "metadata": {},
   "source": [
    "### Training Pipeline Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e24d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion,optimizer,num_epochs=10):\n",
    "    ############################################################\n",
    "    # tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    ############################################################\n",
    "\n",
    "    since = time.time()                                            \n",
    "    batch_ct = 0\n",
    "    example_ct = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        #Training\n",
    "        model.train()\n",
    "        for x,y in train_dl: #BS=32 ([BS,3,224,224], [BS,4])            \n",
    "  \n",
    "            #######################################################################\n",
    "            # The second code snippet does not zero the memory of each individual parameter, \n",
    "            # also the subsequent backward pass uses assignment instead of addition to store gradients,\n",
    "            # this reduces the number of memory operations.\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ######################################################################\n",
    "            \n",
    "            train_logits = model(x) #Input = [BS,3,224,224] (Image) -- Model --> [BS,4] (Output Scores)\n",
    "            _, train_preds = torch.max(train_logits, 1)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "\n",
    "            train_loss.backward() # Backpropagation this is where your W_gradient\n",
    "            loss=train_loss\n",
    "\n",
    "            optimizer.step() # W_new = W_old - LR * W_gradient \n",
    "            example_ct += len(x) \n",
    "            batch_ct += 1\n",
    "            \n",
    "            ########################################################################\n",
    "            # Stores Wandb Logs here\n",
    "            # Report metrics every 25th batch\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "            ########################################################################\n",
    "        \n",
    "        #validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        # Disable gradient calculation for validation or inference using torch.no_rad()\n",
    "        with torch.no_grad():\n",
    "            for x,y in valid_dl:\n",
    "                valid_logits = model(x)\n",
    "                _, valid_preds = torch.max(valid_logits, 1)\n",
    "                valid_loss = criterion(valid_logits,y)\n",
    "                running_loss += valid_loss.item() * x.size(0)\n",
    "                running_corrects += torch.sum(valid_preds == y.data)\n",
    "                total += y.size(0)\n",
    "                ########################################################################\n",
    "                # Test Accuracy Logs\n",
    "                wandb.log({\"test_accuracy\": running_corrects / total})\n",
    "                ########################################################################\n",
    "            \n",
    "        epoch_loss = running_loss / len(valid_ds)\n",
    "        epoch_acc = running_corrects.double() / len(valid_ds)\n",
    "        print(\"Validation Loss is {}\".format(epoch_loss))\n",
    "        print(\"Validation Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    torch.save(model.state_dict(), config.saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cfae335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "    # where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d9302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "Loss after 00768 examples: 0.465\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, num_epochs=config.EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b479f4f9",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
